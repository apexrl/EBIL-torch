constants:
  ebil_params:
    clamp_magnitude: -1
    eval_deterministic: true
    freq_saving: 20
    max_path_length: 1000
    min_steps_before_training: 5000
    mode: ae
    no_terminal: true
    num_epochs: 162
    num_policy_update_loops_per_train_call: 100
    num_policy_updates_per_loop_iter: 1
    num_steps_between_train_calls: 1000
    num_steps_per_epoch: 100000
    num_steps_per_eval: 20000
    policy_optim_batch_size: 256
    policy_optim_batch_size_from_expert: 0
    replay_buffer_size: 20000
    save_algorithm: false
    save_best: true
    save_environment: false
    save_replay_buffer: false
    state_only: false
    use_grad_pen: false
    wrap_absorbing: false
  ebm_hid_act: tanh
  ebm_hid_dim: 256
  ebm_num_blocks: 3
  ebm_use_bn: false
  env_specs:
    env_kwargs: {}
    env_name: hopper
    eval_env_seed: 78236
    training_env_seed: 24495
  expert_idx: 0
  expert_name: norm_hopper_4_demos_sub_20
  expert_traj_num: 4
  policy_net_size: 256
  policy_num_hidden_layers: 2
  rew_func: -energy
  sac_params:
    beta_1: 0.25
    discount: 0.99
    policy_lr: 0.0003
    policy_mean_reg_weight: 0.001
    policy_std_reg_weight: 0.001
    qf_lr: 0.0003
    soft_target_tau: 0.005
    vf_lr: 0.0003
  scale_env_with_demo_stats: true
  test: true
meta_data:
  description: Train an EBIL model in Hopper with AE
  exp_name: ebil_ae_hopper_hype_search
  mem_per_worker: 4gb
  node_exclusions: gpu048,gpu024,gpu025,gpu012,gpu027
  num_cpu_per_worker: 32
  num_gpu_per_worker: 1
  num_workers: 1
  partitions: cpu
  script_path: run_scripts/ebil_exp_script.py
variables:
  ebil_params:
    grad_pen_weight:
    - 0.5
  ebm_epoch:
  - '4000'
  sac_params:
    reward_scale:
    - 0.05
  seed:
  - 723894
